{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sortedcontainers import SortedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Csv File dan cek apakah file nya sudah terbaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  place_id  rating\n",
       "0        1         2       3\n",
       "1        1         7       5\n",
       "2        1         8       5\n",
       "3        1        12       2\n",
       "4        1        13       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://drive.google.com/file/d/1rOPR2Xg4g5P4jxKejzZ1mx20L2Pwb4Ln/view?usp=sharing'\n",
    "file_id = url.split('/')[-2]\n",
    "dwn_url = 'https://drive.google.com/uc?id=' + file_id\n",
    "df = pd.read_csv(dwn_url, sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek apakah terdapat nilai kosong pada kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     0\n",
       "place_id    0\n",
       "rating      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melihat informasi df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   user_id   3000 non-null   int64\n",
      " 1   place_id  3000 non-null   int64\n",
      " 2   rating    3000 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 70.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "userId dari 1...3000, convert jadi userId dari 0...2999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "userID = df.user_id.values\n",
    "print(userID.min())\n",
    "placeID = df.place_id.values\n",
    "print(placeID.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek apakah terdapat Id yang tidak muncul dalam urutan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID place tidak ada yang hilang? True\n",
      "ID user tidak ada yang hilang? True\n"
     ]
    }
   ],
   "source": [
    "def missingIdNum(data):\n",
    "    return [i for i in range(1,len(data)) if data[i-1]!=i]\n",
    "\n",
    "place = np.sort(list(set(df.place_id.values)))\n",
    "user = np.sort(list(set(df.user_id.values)))\n",
    "\n",
    "print('ID place tidak ada yang hilang? {}'.format(len(missingIdNum(place))==0))\n",
    "print('ID user tidak ada yang hilang? {}'.format(len(missingIdNum(user))==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat mapping untuk placeId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_place_ids = set(df.place_id.values) # convert to array -> set (untuk menghapus data duplikat)\n",
    "place2idx = {}\n",
    "count = 0\n",
    "for place_id in unique_place_ids:\n",
    "    place2idx[place_id] = count\n",
    "    count+=1\n",
    "df['place_idx'] = df.apply(lambda row: place2idx[row.place_id], axis=1)\n",
    "\n",
    "unique_user_ids = set(df.user_id.values) # convert to array -> set (untuk menghapus data duplikat)\n",
    "user2idx = {}\n",
    "count = 0\n",
    "for user_id in unique_user_ids:\n",
    "    user2idx[user_id] = count\n",
    "    count+=1\n",
    "df['user_idx'] = df.apply(lambda row: user2idx[row.user_id], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop kolom placeName dan placeId, lalu swap kolom place_idx dengan rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['place_id','user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>place_idx</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>99</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>99</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>99</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>99</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_idx  place_idx  rating\n",
       "0            0          1       3\n",
       "1            0          6       5\n",
       "2            0          7       5\n",
       "3            0         11       2\n",
       "4            0         12       5\n",
       "...        ...        ...     ...\n",
       "2995        99         57       1\n",
       "2996        99         58       5\n",
       "2997        99         64       4\n",
       "2998        99         68       5\n",
       "2999        99         71       5\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "a, b = cols.index('rating'), cols.index('user_idx')\n",
    "cols[a], cols[b] = cols[b], cols[a]\n",
    "df = df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  placeID  rating\n",
       "0       0        1       3\n",
       "1       0        6       5\n",
       "2       0        7       5\n",
       "3       0       11       2\n",
       "4       0       12       5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['userID', 'placeID', 'rating']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 3000\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset size:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyak user: 100\n",
      "Banyak tempat wisata: 75\n"
     ]
    }
   ],
   "source": [
    "N = df.userID.max() + 1 # Banyaknya user\n",
    "M = df.placeID.max() + 1 # Banyaknya tempat wisata\n",
    "print(\"Banyak user:\", N)\n",
    "print(\"Banyak tempat wisata:\", M)\n",
    "\n",
    "# Menghitung banyak nya suatu user disebutkan dalam kolom userID -> semakin banyak, maka user tsb sering merating tempat wisata\n",
    "user_ids_count = Counter(df.userID)\n",
    "# Menghitung banyak nya suatu tempat wisata disebutkan dalam kolom placeID -> semakin banyak, maka tempat wisata tsb sering dirating oleh users\n",
    "place_ids_count = Counter(df.placeID)\n",
    "# Bentuknya menjadi tuple {key:value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banyaknya user dan tempat yang akan disimpan (digunakan untuk small DS)\n",
    "n = 75\n",
    "m = 75\n",
    "\n",
    "user_ids = [u for u, c in user_ids_count.most_common(n)]\n",
    "place_ids = [m for m, c in place_ids_count.most_common(m)]\n",
    "# u,m: key ; c: value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  placeID  rating\n",
       "0          0        1       3\n",
       "1          0        6       5\n",
       "2          0        7       5\n",
       "3          0       11       2\n",
       "4          0       12       5\n",
       "...      ...      ...     ...\n",
       "2245      74       61       5\n",
       "2246      74       62       3\n",
       "2247      74       66       3\n",
       "2248      74       68       2\n",
       "2249      74       72       2\n",
       "\n",
       "[2250 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Membuat small df\n",
    "- userID dan placeID digabungkan menggunakan bitwise operator &\n",
    "- row diambil jika user di user_ids <=> merating tempat wisata di place_ids\n",
    "'''\n",
    "df_small = df[df.userID.isin(user_ids) & df.placeID.isin(place_ids)].copy()\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bikin jadi sequential id nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyak user: 75\n",
      "Banyak tempat wisata: 75\n"
     ]
    }
   ],
   "source": [
    "unique_user_ids = set(df_small.userID.values)\n",
    "new_user_id_map = {}\n",
    "i = 0\n",
    "for old in unique_user_ids:\n",
    "    new_user_id_map[old] = i\n",
    "    i+=1\n",
    "print(\"Banyak user:\", i)\n",
    "\n",
    "unique_place_ids = set(df_small.placeID.values)\n",
    "new_place_id_map = {}\n",
    "j = 0\n",
    "for old in unique_place_ids:\n",
    "    new_place_id_map[old] = j\n",
    "    j+=1\n",
    "print(\"Banyak tempat wisata:\",j)\n",
    "\n",
    "df_small.loc[:,'userID'] = df_small.apply(lambda row: new_user_id_map[row.userID], axis=1)\n",
    "df_small.loc[:,'placeID'] = df_small.apply(lambda row: new_place_id_map[row.placeID], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  placeID  rating\n",
       "0          0        1       3\n",
       "1          0        6       5\n",
       "2          0        7       5\n",
       "3          0       11       2\n",
       "4          0       12       5\n",
       "...      ...      ...     ...\n",
       "2245      74       61       5\n",
       "2246      74       62       3\n",
       "2247      74       66       3\n",
       "2248      74       68       2\n",
       "2249      74       72       2\n",
       "\n",
       "[2250 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max user id: 74\n",
      "max tempat wisata id: 74\n",
      "small df size: 2250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  placeID  rating\n",
       "0          0        1       3\n",
       "1          0        6       5\n",
       "2          0        7       5\n",
       "3          0       11       2\n",
       "4          0       12       5\n",
       "...      ...      ...     ...\n",
       "2245      74       61       5\n",
       "2246      74       62       3\n",
       "2247      74       66       3\n",
       "2248      74       68       2\n",
       "2249      74       72       2\n",
       "\n",
       "[2250 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"max user id:\", df_small.userID.max())\n",
    "print(\"max tempat wisata id:\", df_small.placeID.max())\n",
    "print(\"small df size:\", len(df_small))\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Banyak user: 75\n",
      "Banyak tempat wisata: 75\n"
     ]
    }
   ],
   "source": [
    "N = df_small.userID.max()+1\n",
    "M = df_small.placeID.max()+1\n",
    "\n",
    "count = 0\n",
    "for i in df_small.rating:\n",
    "    if i==0 or i =='0':\n",
    "        count+=1\n",
    "print(count)\n",
    "print(\"Banyak user:\", N)\n",
    "print(\"Banyak tempat wisata:\", M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>placeID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>12</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  placeID  rating\n",
       "0         22       59       5\n",
       "1         71       15       5\n",
       "2          4       16       5\n",
       "3         64       62       4\n",
       "4         60       37       4\n",
       "...      ...      ...     ...\n",
       "2245      12       69       4\n",
       "2246      51       24       5\n",
       "2247       1       30       5\n",
       "2248      47       42       4\n",
       "2249      39        5       5\n",
       "\n",
       "[2250 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = shuffle(df_small)\n",
    "df_small.reset_index(inplace=True, drop=True)\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into data train and data test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% menjadi df train, 20% df test\n",
    "cutoff = int(0.7*len(df_small))\n",
    "df_train = df_small.iloc[:cutoff]\n",
    "df_test = df_small.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1575, 3)\n",
      "(675, 3)\n",
      "      userID  placeID  rating\n",
      "355        0       47       3\n",
      "1350       0       38       3\n",
      "589        0       67       5\n",
      "1295       0       40       5\n",
      "1393       0       30       5\n",
      "...      ...      ...     ...\n",
      "446       74        9       4\n",
      "1197      74       62       3\n",
      "1544      74       49       2\n",
      "13        74        0       1\n",
      "1258      74       25       5\n",
      "\n",
      "[1575 rows x 3 columns]\n",
      "      userID  placeID  rating\n",
      "1614       0       51       2\n",
      "2179       0       49       5\n",
      "2003       0       44       4\n",
      "2071       0       50       5\n",
      "1743       0        7       5\n",
      "...      ...      ...     ...\n",
      "1721      74       24       5\n",
      "1981      74       48       2\n",
      "1646      74       16       1\n",
      "2173      74       68       2\n",
      "2027      74        3       4\n",
      "\n",
      "[675 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24284\\2889892058.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.sort_values(by=['userID'], inplace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24284\\2889892058.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.sort_values(by=['userID'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_train.sort_values(by=['userID'], inplace=True)\n",
    "df_test.sort_values(by=['userID'], inplace=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2250 entries, 0 to 2249\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   userID   2250 non-null   int64\n",
      " 1   placeID  2250 non-null   int64\n",
      " 2   rating   2250 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 52.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_small.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import configparser\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP CLASS\n",
    "\n",
    "Kelas 'Grup' bertanggung jawab untuk menghasilkan grup acak dengan ukuran berbeda: kecil, sedang, dan besar dan melakukan evaluasi terhadap berbagai metode AF, BF, dan WBF yang digunakan untuk merekomendasikan grup ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group:\n",
    "    def __init__(self, members, candidate_items, ratings):\n",
    "        # member ids\n",
    "        self.members = sorted(members)\n",
    "\n",
    "        # List of items yang dapat direkomendasikan.\n",
    "        # List ini seharusnya belum didatangi oleh anggota grup mana pun\n",
    "        self.candidate_items = candidate_items # menyimpan daftar item yang dapat direkomendasikan\n",
    "\n",
    "        self.actual_recos = [] # menyimpan rekomendasi aktual yang dibuat atau diprediksi \n",
    "        self.false_positive = [] # Atribut ini menginisialisasi suatu daftar kosong, digunakan untuk menyimpan item yang keliru dianggap sebagai rekomendasi positif\n",
    "        \n",
    "        # Atribut ini menghitung jumlah peringkat yang diberikan oleh setiap anggota dalam suatu kelompok atau tim\n",
    "        # menghitung jumlah peringkat yang tidak nol untuk setiap anggota\n",
    "        self.ratings_per_member = [np.size(ratings[member].nonzero()) for member in self.members]\n",
    "        \n",
    "\n",
    "        # AF\n",
    "        self.grp_factors_af = []\n",
    "        self.bias_af = 0\n",
    "        self.precision_af = 0\n",
    "        self.recall_af = 0\n",
    "        self.reco_list_af = []\n",
    "\n",
    "        # BF\n",
    "        self.grp_factors_bf = []\n",
    "        self.bias_bf = 0\n",
    "        self.precision_bf = 0\n",
    "        self.recall_bf = 0\n",
    "        self.reco_list_bf = []\n",
    "\n",
    "        # WBF\n",
    "        self.grp_factors_wbf = []\n",
    "        self.bias_wbf = 0\n",
    "        self.precision_wbf = 0\n",
    "        self.recall_wbf = 0\n",
    "        self.weight_matrix_wbf = []\n",
    "        self.reco_list_wbf = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelas 'Config' berfungsi sebagai pembaca konfigurasi yang bertanggung jawab membaca parameter konfigurasi dan menangani pengaturan konfigurasi untuk sistem rekomendasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration reader.\n",
    "class Config:\n",
    "    def __init__(self, config_file_path):\n",
    "        self.config_file_path = config_file_path\n",
    "\n",
    "        configParser = configparser.RawConfigParser()\n",
    "        configParser.read(config_file_path)\n",
    "\n",
    "        # Bali tourism dataset, 80 - 20 train/test ratio, present in data directory\n",
    "        url_trainingData = 'https://drive.google.com/file/d/1-1canNjW1tvxFBfwivedp1O3WRT0vBQB/view?usp=sharing'\n",
    "        url_testData = 'https://drive.google.com/file/d/1--4dU905tmg_rc9AagfoqxVyV2K4UCsq/view?usp=sharing'\n",
    "\n",
    "        fileTrain_id = url_trainingData.split('/')[-2]\n",
    "        dwnTrain_url = 'https://drive.google.com/uc?id=' + fileTrain_id\n",
    "        fileTest_id = url_testData.split('/')[-2]\n",
    "        dwnTest_url = 'https://drive.google.com/uc?id=' + fileTest_id\n",
    "\n",
    "        self.training_file = ps.read_csv(dwnTrain_url)\n",
    "        self.testing_file = ps.read_csv(dwnTest_url)\n",
    "\n",
    "        self.small_grp_size = int(configParser.get('Config', 'small_grp_size'))\n",
    "        self.medium_grp_size = int(configParser.get('Config', 'medium_grp_size'))\n",
    "        self.large_grp_size = int(configParser.get('Config', 'large_grp_size'))\n",
    "\n",
    "        self.max_iterations_mf = int(configParser.get('Config', 'max_iterations_mf'))\n",
    "        self.lambda_mf = float(configParser.get('Config', 'lambda_mf'))\n",
    "        self.learning_rate_mf = float(configParser.get('Config', 'learning_rate_mf'))\n",
    "\n",
    "        self.num_factors = int(configParser.get('Config', 'num_factors'))\n",
    "\n",
    "        #AF (after factorization)\n",
    "        self.rating_threshold_af = float(configParser.get('Config', 'rating_threshold_af'))\n",
    "        self.num_recos_af = int(configParser.get('Config', 'num_recos_af'))\n",
    "\n",
    "        #BF (before factorization)\n",
    "        self.rating_threshold_bf = float(configParser.get('Config', 'rating_threshold_bf'))\n",
    "        self.num_recos_bf = int(configParser.get('Config', 'num_recos_bf'))\n",
    "\n",
    "        #WBF (weighted before factorization)\n",
    "        self.rating_threshold_wbf = float(configParser.get('Config', 'rating_threshold_wbf'))\n",
    "        self.num_recos_wbf = int(configParser.get('Config', 'num_recos_wbf'))\n",
    "\n",
    "        self.is_debug = configParser.getboolean('Config', 'is_debug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat daftar tempat wisata yang dapat direkomendasikan :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi di sini memiliki tujuan untuk mencari item yang belum didatangi oleh semua anggota dalam suatu kelompok. Fungsi ini dapat digunakan untuk menyaring item yang dapat direkomendasikan kepada kelompok tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def find_candidate_items(ratings, members):\n",
    "    if len(members) == 0: return [] # pengecekan apakah ada members kosong\n",
    "\n",
    "    # Membuat daftar indeks item yang belum didatangi oleh anggota pertama dalam daftar anggota \n",
    "    unwatched_items = np.argwhere(ratings[members[0]] == 0) \n",
    "\n",
    "    # Fungsi kemudian melakukan iterasi melalui setiap anggota selain anggota pertama\n",
    "    for member in members:\n",
    "        # daftar indeks item yang belum didatangi oleh anggota saat ini\n",
    "        cur_unwatched = np.argwhere(ratings[member] == 0)\n",
    "        # mengupdate dengan irisan (intersection) dari unwatched_items dan cur_unwatched\n",
    "        unwatched_items = np.intersect1d(unwatched_items, cur_unwatched)\n",
    "\n",
    "    # Fungsi mengembalikan daftar indeks item yang belum ditonton oleh semua anggota dalam kelompok.\n",
    "    return unwatched_items\n",
    "\n",
    "# fungsi ini ditambahkan sebagai metode pada kelas Group\n",
    "Group.find_candidate_items = find_candidate_items\n",
    "# Mencari item yang dapat direkomendasikan kepada anggota kelompok tersebut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi di sini memiliki tujuan untuk mencari item yang belum dievaluasi (belum mendapatkan rating) oleh semua anggota dalam suatu kelompok. Fungsi ini dapat digunakan untuk menyaring item yang belum mendapatkan rating dari anggota kelompok tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def non_testable_items(members, ratings):\n",
    "    # Menginisialisasi suatu daftar indeks yang sesuai dengan item yang belum diuji oleh anggota pertama dalam grup\n",
    "    # untuk mencari indeks item yang belum mendapatkan rating (nilai nol) oleh anggota pertama dalam daftar anggota\n",
    "    non_eval_items = np.argwhere(ratings[members[0]] == 0) \n",
    "    \n",
    "    # melakukan iterasi melalui setiap anggota selain anggota pertama\n",
    "    for member in members:\n",
    "\n",
    "        # Mencari item yang belum dievaluasi oleh anggota tersebut\n",
    "        cur_non_eval_items = np.argwhere(ratings[member] == 0)\n",
    "\n",
    "        #mengambil irisan dengan indeks item yang belum diuji oleh anggota pertama dan anggota saat ini.\n",
    "        non_eval_items = np.intersect1d(non_eval_items, cur_non_eval_items) \n",
    "\n",
    "    # mengembalikan daftar indeks item yang belum dievaluasi oleh semua anggota dalam kelompok\n",
    "    return non_eval_items\n",
    "\n",
    "Group.non_testable_items = non_testable_items\n",
    "# mencari item yang belum dievaluasi oleh anggota kelompok tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATING GROUPS\n",
    "\n",
    "Membuat grup dari pengguna yang tersedia. Untuk evaluasi yang lebih baik dari pendekatan rekomendasi, harus memastikan bahwa ada cukup item untuk diuji. Jadi menetapkan testable_threshold menjadi 10, yang pada dasarnya berarti bahwa setidaknya ada 10 tempat wisata dalam dataset pengujian yang telah diberi rating oleh setidaknya satu anggota grup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi yang didefinisikan di sini memiliki tujuan untuk menghasilkan sejumlah kelompok dengan anggota yang dipilih secara acak, dan memastikan bahwa setiap kelompok memiliki jumlah item yang dapat diuji (testable items) yang memenuhi batas tertentu (testable_threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def generate_groups(cfg, ratings, test_ratings, num_users, count, size, disjoint = True):\n",
    "    avbl_users = [i for i in range(num_users)] # Daftar pengguna yang tersedia, awalnya berisi semua indeks pengguna\n",
    "    groups = [] #  daftar yang akan berisi kelompok-kelompok yang dihasilkan\n",
    "    testable_threshold = 10 #Batas minimum jumlah item yang dapat diuji dalam suatu grup\n",
    "\n",
    "    iter_idx = 0\n",
    "    while iter_idx in range(count):\n",
    "        group_members = np.random.choice(avbl_users, size = size, replace = False) # Memilih anggota-anggota acak dari pengguna yang tersedia\n",
    "        candidate_items = Group.find_candidate_items(ratings, group_members) # mendapatkan item-item yang dapat direkomendasikan kepada grup\n",
    "        non_eval_items = Group.non_testable_items(group_members, test_ratings) # mendapatkan item-item yang tidak dapat dievaluasi oleh grup\n",
    "        testable_items = np.setdiff1d(candidate_items, non_eval_items) # Menghitung item-item yang dapat diuji dengan mengambil perbedaan dari candidate_items, non_eval_items\n",
    "        # Fungsi mencari item yang dapat diuji dengan mengambil perbedaan antara item yang dapat direkomendasikan dan item yang belum dapat diuji\n",
    "\n",
    "        # Fungsi memeriksa apakah ada item yang dapat direkomendasikan dan apakah jumlah item yang dapat diuji memenuhi batas testable_threshold.\n",
    "        if len(candidate_items) != 0 and len(testable_items) >= testable_threshold:\n",
    "            groups += [Group(group_members, candidate_items, ratings)] # membuat kelompok baru dengan anggota dan item yang sesuai \n",
    "            avbl_users = np.setdiff1d(avbl_users, group_members) #  anggota kelompok tersebut dihapus dari daftar pengguna yang tersedia\n",
    "            iter_idx += 1\n",
    "\n",
    "    # mengembalikan daftar kelompok yang telah dibuat.\n",
    "    return groups\n",
    "\n",
    "Group.generate_groups = generate_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION\n",
    "Sekarang grup telah dibentuk, ini adalah metode untuk memprediksi tempat wisata!\n",
    "Threshold untuk rating yang diprediksi untuk suatu item menjadi 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi yang didefinisikan di sini memiliki tujuan untuk menghasilkan rekomendasi aktual (actual recommendations) dan mengidentifikasi item-item yang disarankan tetapi seharusnya tidak disarankan (false positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actual_recommendations(self, ratings, threshold):\n",
    "    # Mendapatkan item-item yang tidak dapat dievaluasi oleh anggota grup menggunakan metode non_testable_items dari kelas Group\n",
    "    non_eval_items = Group.non_testable_items(self.members, ratings) \n",
    "\n",
    "    # Inisialisasi dengan indeks item yang direkomendasikan oleh anggota pertama dalam grup atau belum dinilai (rating 0)\n",
    "    items = np.argwhere(np.logical_or(ratings[self.members[0]] >= threshold, ratings[self.members[0]] == 0)).flatten() \n",
    "\n",
    "    #  Inisialisasi dengan indeks item yang tidak direkomendasikan atau memiliki peringkat di antara 0 dan ambang batas oleh anggota pertama\n",
    "    fp = np.argwhere(np.logical_and(ratings[self.members[0]] > 0, ratings[self.members[0]] < threshold)).flatten() \n",
    "\n",
    "    for member in self.members:\n",
    "        # Mendapatkan item yang direkomendasikan oleh anggota saat ini atau belum dinilai (rating 0).\n",
    "        cur_items = np.argwhere(np.logical_or(ratings[member] >= threshold, ratings[member] == 0)).flatten()\n",
    "        # Menggabungkan indeks item yang tidak direkomendasikan atau memiliki peringkat di antara 0 dan ambang batas oleh anggota saat ini dengan yang telah ditemukan sebelumnya (fp)\n",
    "        fp = np.union1d(fp, np.argwhere(np.logical_and(ratings[member] > 0, ratings[member] < threshold)).flatten())\n",
    "        # Mengambil irisan dari indeks item yang direkomendasikan oleh anggota pertama dan anggota saat ini.\n",
    "        items = np.intersect1d(items, cur_items) \n",
    "\n",
    "    #Menghapus item-item yang tidak dapat dievaluasi dari daftar item yang direkomendasikan.\n",
    "    items = np.setdiff1d(items, non_eval_items) \n",
    "\n",
    "    # Menetapkan daftar item yang sebenarnya direkomendasikan oleh anggota grup ke dalam atribut actual_recos dari objek kelas\n",
    "    self.actual_recos = items\n",
    "    # Menetapkan daftar item yang salah direkomendasikan \n",
    "    self.false_positive = fp \n",
    "\n",
    "Group.generate_actual_recommendations  = generate_actual_recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION\n",
    "\n",
    "Tiga fungsi berikut digunakan untuk evaluasi masing-masing dari ketiga metode AF, BF, dan WBF.\n",
    "Metode evaluasi yang digunakan adalah Precision dan Recall untuk berbagai ukuran grup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_af(self, is_debug=False):\n",
    "    tp = float(np.intersect1d(self.actual_recos, self.reco_list_af).size)\n",
    "    fp = float(np.intersect1d(self.false_positive, self.reco_list_af).size)\n",
    "\n",
    "    try:\n",
    "        self.precision_af = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        self.precision_af = np.NaN\n",
    "\n",
    "    try:\n",
    "        self.recall_af = tp / self.actual_recos.size\n",
    "    except ZeroDivisionError:\n",
    "        self.recall_af = np.NaN\n",
    "\n",
    "    if is_debug:\n",
    "        print('tp: ', tp)\n",
    "        print('fp: ', fp)\n",
    "        print('precision_af: ', self.precision_af)\n",
    "        print('recall_af: ', self.recall_af)\n",
    "\n",
    "    return self.precision_af, self.recall_af, tp, fp\n",
    "Group.evaluate_af = evaluate_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bf(self, is_debug=False):\n",
    "    tp = float(np.intersect1d(self.actual_recos, self.reco_list_bf).size)\n",
    "    fp = float(np.intersect1d(self.false_positive, self.reco_list_bf).size)\n",
    "\n",
    "    try:\n",
    "        self.precision_bf = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        self.precision_bf = np.NaN\n",
    "\n",
    "    try:\n",
    "        self.recall_bf = tp / self.actual_recos.size\n",
    "    except ZeroDivisionError:\n",
    "        self.recall_bf = np.NaN\n",
    "\n",
    "    if is_debug:\n",
    "        print('tp: ', tp)\n",
    "        print('fp: ', fp)\n",
    "        print('precision_bf: ', self.precision_bf)\n",
    "        print('recall_bf: ', self.recall_bf)\n",
    "\n",
    "    return self.precision_bf, self.recall_bf, tp, fp\n",
    "Group.evaluate_bf = evaluate_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_wbf(self, is_debug=False):\n",
    "    tp = float(np.intersect1d(self.actual_recos, self.reco_list_wbf).size)\n",
    "    fp = float(np.intersect1d(self.false_positive, self.reco_list_wbf).size)\n",
    "\n",
    "    try:\n",
    "        self.precision_wbf = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        self.precision_wbf = np.NaN\n",
    "\n",
    "    try:\n",
    "        self.recall_wbf = tp / self.actual_recos.size\n",
    "    except ZeroDivisionError:\n",
    "        self.recall_wbf = np.NaN\n",
    "\n",
    "    if is_debug:\n",
    "        print('tp: ', tp)\n",
    "        print('fp: ', fp)\n",
    "        print('precision_bf: ', self.precision_wbf)\n",
    "        print('recall_bf: ', self.recall_wbf)\n",
    "\n",
    "    return self.precision_wbf, self.recall_wbf, tp, fp\n",
    "Group.evaluate_wbf = evaluate_wbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregator Class :\n",
    "\n",
    "Kelas ini bertanggung jawab untuk menentukan cara yang berbeda untuk mengagregasi faktor untuk anggota grup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregators:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    #pass ratings or factors as input\n",
    "    @staticmethod\n",
    "    def average(arr): # menghitung rata-rata dari matriks input\n",
    "        return np.average(arr, axis = 0, weights = None)\n",
    "\n",
    "    @staticmethod\n",
    "    def average_bf(arr): # menghitung rata-rata dari matriks input, tetapi mengabaikan nilai nol (0) dalam perhitungannya\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            arr[arr == 0] = np.nan\n",
    "            return np.nanmean(arr, axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def weighted_average(arr, weights): # Menghitung rata-rata terbobot dari matriks input menggunakan bobot yang diberikan.\n",
    "        return np.average(arr, axis = 0, weights = weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupRec Class :\n",
    "\n",
    "Ini adalah class utama yang bertanggung jawab untuk membaca data, menentukan metode untuk pendekatan, dan mengevaluasinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overflow warnings should be raised as errors\n",
    "np.seterr(over='raise')\n",
    "\n",
    "class GroupRec:\n",
    "    def __init__(self):\n",
    "        self.cfg = Config(r\"config.conf\")\n",
    "\n",
    "        # training and testing matrices\n",
    "        self.ratings = None\n",
    "        self.test_ratings = None\n",
    "\n",
    "        self.groups = []\n",
    "\n",
    "        # read data into above matrices\n",
    "        self.read_data()\n",
    "\n",
    "        self.num_users = self.ratings.shape[0]\n",
    "        self.num_items = self.ratings.shape[1]\n",
    "\n",
    "        # predicted ratings matrix based on factors.\n",
    "        self.predictions = np.zeros((self.num_users, self.num_items))\n",
    "\n",
    "        # output after svd factorization\n",
    "        # initialize all unknowns with random values from -1 to 1\n",
    "        self.user_factors = np.random.uniform(-1, 1, (self.ratings.shape[0], self.cfg.num_factors))\n",
    "        self.item_factors = np.random.uniform(-1, 1, (self.ratings.shape[1], self.cfg.num_factors))\n",
    "\n",
    "        self.user_biases = np.zeros(self.num_users)\n",
    "        self.item_biases = np.zeros(self.num_items)\n",
    "\n",
    "        # global mean of ratings a.k.a mu\n",
    "        self.ratings_global_mean = 0\n",
    "\n",
    "    # add list of groups\n",
    "    def add_groups(self, groups):\n",
    "        self.groups = groups\n",
    "\n",
    "    # remove groups\n",
    "    def remove_groups(self, groups):\n",
    "        self.groups = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "\n",
    "Menggunakan library 'pandas' untuk membaca data test dan data train dari file csv. Setelah itu membuat matriks rating item * pengguna di sini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training and testing data into matrices\n",
    "def read_data(self):\n",
    "  column_headers = ['userID', 'placeID', 'rating']\n",
    "\n",
    "  url_trainingData = r'https://drive.google.com/file/d/1-1canNjW1tvxFBfwivedp1O3WRT0vBQB/view?usp=sharing'\n",
    "  url_testData = r'https://drive.google.com/file/d/1--4dU905tmg_rc9AagfoqxVyV2K4UCsq/view?usp=sharing'\n",
    "\n",
    "\n",
    "  fileTrain_id = url_trainingData.split('/')[-2]\n",
    "  dwnTrain_url = 'https://drive.google.com/uc?id=' + fileTrain_id\n",
    "  print('Reading training data from...')\n",
    "  training_data = ps.read_csv(dwnTrain_url)\n",
    "\n",
    "  fileTest_id = url_testData.split('/')[-2]\n",
    "  dwnTest_url = 'https://drive.google.com/uc?id=' + fileTest_id\n",
    "  print('Reading testing data...')\n",
    "  testing_data = ps.read_csv(dwnTest_url)\n",
    "\n",
    "  num_users = max(training_data.userID.unique())\n",
    "  num_items = max(training_data.placeID.unique())\n",
    "\n",
    "  self.ratings = np.zeros((num_users, num_items))\n",
    "  self.test_ratings = np.zeros((num_users, num_items))\n",
    "\n",
    "\n",
    "  for row in training_data.itertuples(index=False):\n",
    "      self.ratings[row.userID - 1, row.placeID - 1] = row.rating\n",
    "\n",
    "  for row in testing_data.itertuples(index=False):\n",
    "      self.test_ratings[row.userID - 1, row.placeID - 1] = row.rating\n",
    "\n",
    "GroupRec.read_data = read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization :\n",
    "\n",
    "Memfaktorkan matriks rating. Menggunakan gradient descent untuk meminimalkan kesalahan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_factorize(self):\n",
    "    #solve for these for matrix ratings\n",
    "    ratings_row, ratings_col = self.ratings.nonzero()\n",
    "    num_ratings = len(ratings_row)\n",
    "    learning_rate = self.cfg.learning_rate_mf\n",
    "    regularization = self.cfg.lambda_mf\n",
    "\n",
    "    self.ratings_global_mean = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "\n",
    "    print('Doing matrix factorization...')\n",
    "    try:\n",
    "        for iter in range(self.cfg.max_iterations_mf):\n",
    "            print('Iteration: ', iter)\n",
    "            rating_indices = np.arange(num_ratings)\n",
    "            np.random.shuffle(rating_indices)\n",
    "\n",
    "            for idx in rating_indices:\n",
    "                user = ratings_row[idx]\n",
    "                item = ratings_col[idx]\n",
    "\n",
    "                pred = self.predict_user_rating(user, item)\n",
    "                error = self.ratings[user][item] - pred\n",
    "\n",
    "                self.user_factors[user] += learning_rate \\\n",
    "                                            * ((error * self.item_factors[item]) - (regularization * self.user_factors[user]))\n",
    "                self.item_factors[item] += learning_rate \\\n",
    "                                            * ((error * self.user_factors[user]) - (regularization * self.item_factors[item]))\n",
    "\n",
    "                self.user_biases[user] += learning_rate * (error - regularization * self.user_biases[user])\n",
    "                self.item_biases[item] += learning_rate * (error - regularization * self.item_biases[item])\n",
    "\n",
    "            self.sgd_mse()\n",
    "\n",
    "    except FloatingPointError:\n",
    "        print('Floating point Error: ')\n",
    "GroupRec.sgd_factorize = sgd_factorize\n",
    "\n",
    "\n",
    "def sgd_mse(self):\n",
    "    self.predict_all_ratings() # Membuat prediksi untuk semua peringkat \n",
    "\n",
    "    # Mengambil peringkat yang telah diprediksi dan rating aktual dari data pelatihan\n",
    "    predicted_training_ratings = self.predictions[self.ratings.nonzero()].flatten() \n",
    "    # Mengambil peringkat yang telah diprediksi dan rating aktual dari data pengujian.\n",
    "    actual_training_ratings = self.ratings[self.ratings.nonzero()].flatten() \n",
    "\n",
    "    predicted_test_ratings = self.predictions[self.test_ratings.nonzero()].flatten()\n",
    "    actual_test_ratings = self.test_ratings[self.test_ratings.nonzero()].flatten()\n",
    "\n",
    "    training_mse = mean_squared_error(predicted_training_ratings, actual_training_ratings)\n",
    "    print('training mse: ', training_mse)\n",
    "    test_mse = mean_squared_error(predicted_test_ratings, actual_test_ratings)\n",
    "    print('test mse: ', test_mse)\n",
    "GroupRec.sgd_mse = sgd_mse\n",
    "\n",
    "\n",
    "def predict_user_rating(self, user, item): # menghitung prediksi peringkat untuk suatu pengguna pada suatu item\n",
    "    prediction = self.ratings_global_mean + self.user_biases[user] + self.item_biases[item]\n",
    "    prediction += self.user_factors[user, :].dot(self.item_factors[item, :].T)\n",
    "    return prediction\n",
    "GroupRec.predict_user_rating = predict_user_rating\n",
    "\n",
    "def predict_group_rating(self, group, item, method): \n",
    "    if (method == 'af'):\n",
    "        factors = group.grp_factors_af; bias_group = group.bias_af\n",
    "    elif (method == 'bf'):\n",
    "        factors = group.grp_factors_bf; bias_group = group.bias_bf\n",
    "    elif (method == 'wbf'):\n",
    "        factors = group.grp_factors_wbf; bias_group = group.bias_wbf\n",
    "\n",
    "    return self.ratings_global_mean + bias_group + self.item_biases[item] \\\n",
    "                                    + np.dot(factors.T, self.item_factors[item])\n",
    "GroupRec.predict_group_rating = predict_group_rating\n",
    "\n",
    "def predict_all_ratings(self): # menghitung prediksi peringkat untuk suatu grup pada suatu item\n",
    "    for user in range(self.num_users):\n",
    "        for item in range(self.num_items):\n",
    "            self.predictions[user, item] = self.predict_user_rating(user, item)\n",
    "GroupRec.predict_all_ratings = predict_all_ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Factorization (AF) Method Definition....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AF method\n",
    "def af_runner(self, groups = None, aggregator = Aggregators.average):\n",
    "    #if groups is not passed, use self.groups\n",
    "    if (groups is None):\n",
    "        groups = self.groups\n",
    "\n",
    "    #calculate factors\n",
    "    for group in groups:\n",
    "        member_factors = self.user_factors[group.members, :]\n",
    "        member_biases = self.user_biases[group.members]\n",
    "\n",
    "        #aggregate the factors\n",
    "        if (aggregator == Aggregators.average):\n",
    "            group.grp_factors_af = aggregator(member_factors)\n",
    "            group.bias_af = aggregator(member_biases)\n",
    "        elif (aggregator == Aggregators.weighted_average):\n",
    "            group.grp_factors_af = aggregator(member_factors, weights = group.ratings_per_member)\n",
    "            group.bias_af = aggregator(member_biases, weights = group.ratings_per_member)\n",
    "\n",
    "        #predict ratings for all candidate items\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(group.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(group, item, 'af')\n",
    "\n",
    "            if (cur_rating > self.cfg.rating_threshold_af):\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        #sort and filter to keep top 'num_recos_af' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[:self.cfg.num_recos_af]\n",
    "\n",
    "        group.reco_list_af = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "GroupRec.af_runner = af_runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Factorization(BF) Method....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bf_runner(self, groups=None, aggregator=Aggregators.average_bf):\n",
    "    \n",
    "    # aggregate user ratings into virtual group\n",
    "    # calculate factors of group\n",
    "    lamb = self.cfg.lambda_mf\n",
    "\n",
    "    for group in groups:\n",
    "        all_attractions = np.arange(len(self.ratings.T))\n",
    "        watched_items = sorted(list(set(all_attractions) - set(group.candidate_items)))\n",
    "\n",
    "        group_rating = self.ratings[group.members, :]\n",
    "        agg_rating = aggregator(group_rating)\n",
    "        s_g = []\n",
    "        for j in watched_items:\n",
    "            s_g.append(agg_rating[j] - self.ratings_global_mean - self.item_biases[j])\n",
    "\n",
    "        # creating matrix A : contains rows of [item_factors of items in watched_list + '1' vector]\n",
    "        A = np.zeros((0, self.cfg.num_factors))\n",
    "\n",
    "        for item in watched_items:\n",
    "            A = np.vstack([A, self.item_factors[item]])\n",
    "        v = np.ones((len(watched_items), 1))\n",
    "        A = np.c_[A, v]\n",
    "\n",
    "        factor_n_bias = np.dot(np.linalg.inv(np.dot(A.T, A) + lamb * np.identity(self.cfg.num_factors + 1)), np.dot(A.T, s_g))\n",
    "        group.grp_factors_bf = factor_n_bias[:-1]\n",
    "        group.bias_bf = factor_n_bias[-1]\n",
    "\n",
    "        # Making recommendations on candidate list :\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(group.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(group, item, 'bf')\n",
    "\n",
    "            if (cur_rating > self.cfg.rating_threshold_bf):\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        # sort and filter to keep top 'num_recos_bf' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[\n",
    "                                  :self.cfg.num_recos_bf]\n",
    "\n",
    "        group.reco_list_bf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "GroupRec.bf_runner = bf_runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Before Factorization Method (WBF)....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wbf_runner(self, groups=None, aggregator=Aggregators.average_bf):\n",
    "    # aggregate user ratings into virtual group\n",
    "    # calculate factors of group\n",
    "    lamb = self.cfg.lambda_mf\n",
    "    for group in groups:\n",
    "        all_attractions = np.arange(len(self.ratings.T))\n",
    "        watched_items = sorted(list(set(all_attractions) - set(group.candidate_items)))\n",
    "\n",
    "        group_rating = self.ratings[group.members, :]\n",
    "        agg_rating = aggregator(group_rating)\n",
    "        s_g = []\n",
    "        for j in watched_items:\n",
    "            s_g.append(agg_rating[j] - self.ratings_global_mean - self.item_biases[j])\n",
    "\n",
    "        # creating matrix A : contains rows of [item_factors of items in watched_list + '1' vector]\n",
    "        A = np.zeros((0, self.cfg.num_factors))  # 3 is the number of features here = K\n",
    "\n",
    "        for item in watched_items:\n",
    "            A = np.vstack([A, self.item_factors[item]])\n",
    "        v = np.ones((len(watched_items), 1))\n",
    "        A = np.c_[A, v]\n",
    "\n",
    "        wt = []\n",
    "        for item in watched_items:\n",
    "            rated = np.argwhere(self.ratings[:, item] != 0)  # list of users who have rated this place\n",
    "            watched = np.intersect1d(rated, group.members)  # list of group members who have watched this place\n",
    "            std_dev = np.std(self.ratings[:, item][self.ratings[:, item] != 0])  # std deviation for the rating of the item\n",
    "            wt += [len(watched) / float(len(group.members)) * 1 / (1 + std_dev)]  # list containing diagonal elements\n",
    "        W = np.diag(wt)  # diagonal weight matrix\n",
    "\n",
    "        factor_n_bias = np.dot(np.linalg.inv(np.dot(np.dot(A.T, W),A) + lamb * np.identity(self.cfg.num_factors + 1)),\n",
    "                               np.dot(np.dot(A.T, W), s_g))\n",
    "        group.grp_factors_wbf = factor_n_bias[:-1]\n",
    "        group.bias_wbf = factor_n_bias[-1]\n",
    "\n",
    "        # Making recommendations on candidate list :\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(group.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(group, item, 'wbf')\n",
    "\n",
    "            if (cur_rating > self.cfg.rating_threshold_wbf):\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        # sort and filter to keep top 'num_recos_wbf' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[\n",
    "                                  :self.cfg.num_recos_wbf]\n",
    "\n",
    "        group.reco_list_wbf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "GroupRec.wbf_runner = wbf_runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating methods......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(self):\n",
    "    # For AF\n",
    "    af_precision_list = []\n",
    "    af_recall_list = []\n",
    "    print(\"\\n#########-------For AF-------#########\")\n",
    "    for grp in self.groups:\n",
    "        grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_af)\n",
    "        (precision, recall, tp, fp) = grp.evaluate_af()\n",
    "        af_precision_list.append(precision)\n",
    "        af_recall_list.append(recall)\n",
    "\n",
    "    af_mean_precision = np.nanmean(np.array(af_precision_list))\n",
    "    af_mean_recall = np.nanmean(np.array(af_recall_list))\n",
    "    print('\\nAF method: mean precision: ', af_mean_precision)\n",
    "    print('AF method: mean recall: ', af_mean_recall)\n",
    "\n",
    "    # For BF\n",
    "    bf_precision_list = []\n",
    "    bf_recall_list = []\n",
    "    print(\"\\n#########-------For BF-------#########\")\n",
    "    for grp in self.groups:\n",
    "        grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_bf)\n",
    "        (precision, recall, tp, fp) = grp.evaluate_bf()\n",
    "        bf_precision_list.append(precision)\n",
    "        bf_recall_list.append(recall)\n",
    "\n",
    "    bf_mean_precision = np.nanmean(np.array(bf_precision_list))\n",
    "    bf_mean_recall = np.nanmean(np.array(bf_recall_list))\n",
    "    print('\\nBF method: mean precision: ', bf_mean_precision)\n",
    "    print('BF method: mean recall: ', bf_mean_recall)\n",
    "\n",
    "    # For WBF\n",
    "    wbf_precision_list = []\n",
    "    wbf_recall_list = []\n",
    "    print(\"\\n#########-------For WBF-------#########\")\n",
    "    for grp in self.groups:\n",
    "        grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_wbf)\n",
    "        (precision, recall, tp, fp) = grp.evaluate_wbf()\n",
    "        wbf_precision_list.append(precision)\n",
    "        wbf_recall_list.append(recall)\n",
    "\n",
    "    wbf_mean_precision = np.nanmean(np.array(wbf_precision_list))\n",
    "    wbf_mean_recall = np.nanmean(np.array(wbf_recall_list))\n",
    "    print('\\nWBF method: mean precision: ', wbf_mean_precision)\n",
    "    print('WBF method: mean recall: ', wbf_mean_recall)\n",
    "GroupRec.evaluation = evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all our proposed methods and evaluating them altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_methods(self, groups):\n",
    "    if (groups is None):\n",
    "        groups = self.groups\n",
    "    #PS: could call them without passing groups as we have already added groups to grouprec object\n",
    "    self.af_runner(groups, Aggregators.weighted_average)\n",
    "    self.bf_runner(groups, Aggregators.average_bf)\n",
    "    self.wbf_runner(groups, Aggregators.average_bf)\n",
    "\n",
    "    #evaluation\n",
    "    self.evaluation()\n",
    "GroupRec.run_all_methods = run_all_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAM\n",
    "\n",
    "Pertama, faktorisasi matriks dengan metode Stochastic Gradient Descent (SGD). Jumlah iterasi diambil dari config dan MSE selama iterasi dilaporkan. Di sini hanya melakukan 3 iterasi dalam demo ini sehingga mse(error) lebih tinggi. Untuk hasil, saya telah melakukan lebih banyak iterasi untuk mendapatkan mse yang lebih rendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data from...\n",
      "Reading testing data...\n",
      "3\n",
      "Doing matrix factorization...\n",
      "Iteration:  0\n",
      "training mse:  0.6808502897310343\n",
      "test mse:  1.5011080420873044\n",
      "Iteration:  1\n",
      "training mse:  0.4594587417300548\n",
      "test mse:  1.3508815699939087\n",
      "Iteration:  2\n",
      "training mse:  0.3580973471489492\n",
      "test mse:  1.2975625384201053\n"
     ]
    }
   ],
   "source": [
    "gr = GroupRec()\n",
    "print(gr.cfg.max_iterations_mf)\n",
    "gr.sgd_factorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate small, medium and large groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Running for  small  groups *************\n",
      "generated groups (only first 3 are getting printed here): \n",
      "[1, 34, 56]\n",
      "[17, 23, 65]\n",
      "[7, 13, 15]\n",
      "\n",
      "******* Running for  medium  groups *************\n",
      "generated groups (only first 3 are getting printed here): \n",
      "[7, 23, 32, 69, 73]\n",
      "[4, 43, 67, 68, 70]\n",
      "[6, 10, 11, 28, 54]\n",
      "\n",
      "******* Running for  large  groups *************\n",
      "generated groups (only first 3 are getting printed here): \n",
      "[3, 10, 15, 32, 40, 43, 45, 48, 63, 67]\n",
      "[0, 11, 23, 24, 25, 34, 35, 36, 54, 65]\n",
      "[2, 4, 33, 39, 44, 46, 60, 62, 69, 70]\n"
     ]
    }
   ],
   "source": [
    "#generate groups programmatically\n",
    "#disjoint means none of the groups shares any common members\n",
    "\n",
    "small_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.small_grp_size, disjoint=True)\n",
    "medium_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.medium_grp_size, disjoint=True)\n",
    "large_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.large_grp_size, disjoint=True)\n",
    "\n",
    "group_set = [small_groups, medium_groups, large_groups]\n",
    "group_type = ['small', 'medium', 'large']\n",
    "\n",
    "for idx, groups in enumerate(group_set):\n",
    "    if groups is []:\n",
    "        continue\n",
    "\n",
    "    # generated groups\n",
    "    n = 3\n",
    "    print('\\n******* Running for ', group_type[idx], ' groups *************')\n",
    "    print('generated groups (only first %d are getting printed here): ' % n)\n",
    "    for group in groups[:n]:\n",
    "        print(group.members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all the methods (AF, BF and WBF) for all the 3 group sizes and report the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Running for  small  groups *************\n",
      "[22, 20, 19]\n",
      "[22, 17, 21]\n",
      "[20, 21, 21]\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.8425925925925926\n",
      "AF method: mean recall:  0.2981366459627329\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.8425925925925926\n",
      "BF method: mean recall:  0.32850241545893716\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.8333333333333334\n",
      "WBF method: mean recall:  0.31262939958592134\n",
      "\n",
      "******* Running for  medium  groups *************\n",
      "[20, 17, 19, 22, 35]\n",
      "[22, 23, 21, 23, 18]\n",
      "[21, 20, 16, 22, 18]\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.7071428571428572\n",
      "AF method: mean recall:  0.15642071437399577\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.5992063492063492\n",
      "BF method: mean recall:  0.11230997404523546\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.6944444444444445\n",
      "WBF method: mean recall:  0.1675318254851069\n",
      "\n",
      "******* Running for  large  groups *************\n",
      "[15, 20, 21, 19, 24, 23, 16, 21, 26, 21]\n",
      "[20, 16, 17, 18, 21, 20, 22, 21, 18, 21]\n",
      "[20, 22, 20, 16, 20, 18, 19, 21, 22, 18]\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.7777777777777778\n",
      "AF method: mean recall:  0.11096255480827233\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.7777777777777778\n",
      "BF method: mean recall:  0.07069929503281744\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.7222222222222223\n",
      "WBF method: mean recall:  0.07863580296932536\n"
     ]
    }
   ],
   "source": [
    "for idx, groups in enumerate(group_set):\n",
    "    if groups is []:\n",
    "        continue\n",
    "    print('\\n******* Running for ', group_type[idx], ' groups *************')\n",
    "    gr.add_groups(groups)\n",
    "    for i in groups:\n",
    "        print(i.ratings_per_member)\n",
    "    gr.run_all_methods(groups)\n",
    "    gr.remove_groups(groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
